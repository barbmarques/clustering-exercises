{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zillow\n",
    "\n",
    "For the following, iterate through the steps you would take to create functions: Write the code to do the following in a jupyter notebook, test it, convert to functions, then create the file to house those functions.\n",
    "\n",
    "You will have a zillow.ipynb file and a helper file for each section in the pipeline.\n",
    "\n",
    "\n",
    "**acquire & summarize**\n",
    "\n",
    "1. Acquire data from mySQL using the python module to connect and query. You will want to end with a single dataframe. Make sure to include: the logerror, all fields related to the properties that are available. You will end up using all the tables in the database.\n",
    "\n",
    "    - Be sure to do the correct join (inner, outer, etc.). We do not want to eliminate properties purely because they may have a null value for airconditioningtypeid.\n",
    "    \n",
    "    - Only include properties with a transaction in 2017, and include only the last transaction for each property (so no duplicate property ID's), along with zestimate error and date of transaction.\n",
    "    \n",
    "    - Only include properties that include a latitude and longitude value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import env\n",
    "\n",
    "# Clear pink warning boxes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Handle large numbers w/o using scientific notation\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import env\n",
    "\n",
    "# connection function for accessing mysql \n",
    "def get_connection(db, user=env.user, host=env.host, password=env.password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "def acquire(df):\n",
    "    '''\n",
    "    This function connects to Codeup's SQL Server using given parameters in the user's\n",
    "    env file.  It then uses a SQL query to acquire all data from Zillow's database that has a transaction data in 2017 and\n",
    "    has longitude and latitude information on the property.\n",
    "    \n",
    "    It returns all the data in a single dataframe called df.\n",
    "    '''\n",
    "    \n",
    "    def get_connection(db, user=env.user, host=env.host, password=env.password):\n",
    "         return f'mysql+pymysql://{user}:{password}@{host}/{db}'\n",
    "    query = '''\n",
    "            SELECT *\n",
    "FROM properties_2016 \n",
    "\tleft outer join properties_2017 using (parcelid)\n",
    "\tleft outer join predictions_2017 using (parcelid)\n",
    "\tleft outer join airconditioningtype as ac ON (properties_2017.airconditioningtypeid = ac.airconditioningtypeid)\n",
    "\tleft outer join architecturalstyletype as ar on (properties_2017.architecturalstyletypeid = ar.architecturalstyletypeid)\n",
    "\tleft outer join buildingclasstype as bc on (properties_2017.buildingclasstypeid = bc.buildingclasstypeid)\n",
    "\tleft outer join heatingorsystemtype on (properties_2017.heatingorsystemtypeid = heatingorsystemtype.heatingorsystemtypeid)\n",
    "\tLEFT OUTER JOIN propertylandusetype on (properties_2017.propertylandusetypeid = propertylandusetype.propertylandusetypeid)\n",
    "\tLEFT OUTER JOIN storytype on (properties_2017.storytypeid = storytype.storytypeid)\n",
    "\tLEFT OUTER JOIN typeconstructiontype on (properties_2017.typeconstructiontypeid = typeconstructiontype.typeconstructiontypeid)\n",
    "UNION ALL\n",
    "SELECT *\n",
    "FROM properties_2016 \n",
    "\tRIGHT OUTER JOIN properties_2017 using(parcelid)\n",
    "\tRIGHT OUTER JOIN predictions_2017 using(parcelid)\n",
    "\tRIGHT OUTER JOIN airconditioningtype ON (properties_2017.airconditioningtypeid = airconditioningtype.airconditioningtypeid)\n",
    "\tRIGHT OUTER JOIN architecturalstyletype on (properties_2017.architecturalstyletypeid = architecturalstyletype.architecturalstyletypeid)\n",
    "\tRIGHT OUTER JOIN buildingclasstype on (properties_2017.buildingclasstypeid = buildingclasstype.buildingclasstypeid)\n",
    "\tRIGHT OUTER JOIN heatingorsystemtype on (properties_2017.heatingorsystemtypeid = heatingorsystemtype.heatingorsystemtypeid)\n",
    "\tRIGHT OUTER JOIN propertylandusetype on (properties_2017.propertylandusetypeid = propertylandusetype.propertylandusetypeid)\n",
    "\tRIGHT OUTER JOIN storytype on (properties_2017.storytypeid = storytype.storytypeid)\n",
    "\tRIGHT OUTER JOIN typeconstructiontype on (properties_2017.typeconstructiontypeid = typeconstructiontype.typeconstructiontypeid)\n",
    "WHERE ((properties_2017.longitude is not null) and (properties_2017.latitude is not null) and (properties_2016.longitude is not null) \n",
    "    and (properties_2016.latitude is not null) and (predictions_2017.transactiondate like '2017%'));\n",
    "            '''\n",
    "\n",
    "    df = pd.read_sql(query, get_connection('zillow'))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Summarize your data (summary stats, info, dtypes, shape, distributions, value_counts, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  Write a function that takes in a dataframe of observations and attributes and returns a dataframe where each row is an attribute name, the first column is the number of rows with missing values for that attribute, and the second column is percent of total rows that have missing values for that attribute. Run the function and document takeaways from this on how you want to handle missing values.\n",
    "\n",
    "Example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes in a dataframe and returns a dataframe with 3 columns: the number of columns missing, percent of columns missing, and number of rows with n columns missing. Run the function and document takeaways from this on how you want to handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
